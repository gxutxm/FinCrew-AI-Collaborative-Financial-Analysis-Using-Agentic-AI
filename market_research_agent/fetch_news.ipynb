{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e24aec25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All libraries loaded and API key ready\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import re\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "# Visualization imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "# Configure matplotlib\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "# Load API key\n",
    "load_dotenv()\n",
    "finnhub_key = os.getenv(\"FINNHUB_API_KEY\")\n",
    "if not finnhub_key:\n",
    "    raise ValueError(\"‚ö†Ô∏è Please add your FINNHUB_API_KEY to .env file\")\n",
    "print(\"‚úÖ All libraries loaded and API key ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef5d1c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    text = text.strip()\n",
    "    text = re.sub(r\"[^\\w\\s.,?!]\", \"\", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    return text\n",
    "\n",
    "# Initialize VADER\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Function to classify sentiment\n",
    "def get_sentiment_vader(text):\n",
    "    scores = analyzer.polarity_scores(text)\n",
    "    compound = scores['compound']\n",
    "    if compound >= 0.05:\n",
    "        return \"Bullish\"\n",
    "    elif compound <= -0.05:\n",
    "        return \"Bearish\"\n",
    "    else:\n",
    "        return \"Neutral\"\n",
    "\n",
    "def extract_keywords(news_list):\n",
    "    \"\"\"Extract top 10 keywords from headlines\"\"\"\n",
    "    stop_words = {'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for',\n",
    "                  'of', 'with', 'is', 'are', 'was', 'were', 'be', 'been', 'has', 'have'}\n",
    "    all_words = []\n",
    "    for item in news_list:\n",
    "        words = re.findall(r'\\b[a-z]{4,}\\b', item['title'].lower())\n",
    "        all_words.extend([w for w in words if w not in stop_words])\n",
    "    return Counter(all_words).most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "146271d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Summary and Earnings functions ready\n"
     ]
    }
   ],
   "source": [
    "def generate_summary(ticker, news, overall_signal, top_keywords):\n",
    "    \"\"\"Generate a readable summary from headlines\"\"\"\n",
    "    total = len(news)\n",
    "    sentiments = [get_sentiment_vader(item['title']) for item in news]\n",
    "    bullish = sentiments.count('Bullish')\n",
    "    bearish = sentiments.count('Bearish')\n",
    "\n",
    "    # Build keyword phrase\n",
    "    keyword_phrase = \", \".join([word for word, count in top_keywords[:5]])\n",
    "\n",
    "    # Build summary based on overall signal\n",
    "    if overall_signal == \"Bullish\":\n",
    "        signal_text = f\"Positive momentum detected with {bullish} out of {total} headlines showing bullish sentiment.\"\n",
    "    elif overall_signal == \"Bearish\":\n",
    "        signal_text = f\"Negative pressure detected with {bearish} out of {total} headlines showing bearish sentiment.\"\n",
    "    else:\n",
    "        signal_text = f\"No clear direction with {bullish} bullish and {bearish} bearish headlines out of {total} total.\"\n",
    "\n",
    "    summary = (\n",
    "        f\"{ticker} Market Summary\\n\"\n",
    "        f\"{'=' * 50}\\n\"\n",
    "        f\"Signal: {overall_signal}\\n\"\n",
    "        f\"{signal_text}\\n\"\n",
    "        f\"Key Topics: {keyword_phrase}\\n\"\n",
    "        f\"{'=' * 50}\\n\"\n",
    "    )\n",
    "\n",
    "    return summary\n",
    "\n",
    "\n",
    "def fetch_earnings(ticker):\n",
    "    \"\"\"Fetch earnings data from Finnhub\"\"\"\n",
    "    url = f\"https://finnhub.io/api/v1/earnings?symbol={ticker}&token={finnhub_key}\"\n",
    "    try:\n",
    "        data = requests.get(url).json()\n",
    "        earnings = data.get(\"earnings\", [])\n",
    "        if earnings:\n",
    "            latest = earnings[0]\n",
    "            return {\n",
    "                \"symbol\": latest.get(\"symbol\", \"N/A\"),\n",
    "                \"actual_eps\": latest.get(\"actual\", \"N/A\"),\n",
    "                \"estimated_eps\": latest.get(\"estimate\", \"N/A\"),\n",
    "                \"surprise\": latest.get(\"surprise\", \"N/A\"),\n",
    "                \"surprise_percent\": latest.get(\"surprisePercent\", \"N/A\"),\n",
    "                \"reported_date\": latest.get(\"reportedDate\", \"N/A\")\n",
    "            }\n",
    "        else:\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching earnings: {e}\")\n",
    "        return None\n",
    "\n",
    "print(\"‚úÖ Summary and Earnings functions ready\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c80636df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_news(ticker, from_date=\"2026-01-10\", to_date=\"2026-01-14\"):\n",
    "    url = f\"https://finnhub.io/api/v1/company-news?symbol={ticker}&from={from_date}&to={to_date}&token={finnhub_key}\"\n",
    "    try:\n",
    "        data = requests.get(url).json()\n",
    "    except Exception as e:\n",
    "        print(\"Error fetching news:\", e)\n",
    "        return []\n",
    "    headlines = []\n",
    "    for item in data[:10]:\n",
    "        title = clean_text(item.get(\"headline\", \"\"))\n",
    "        link = item.get(\"url\", \"\")\n",
    "        headlines.append({\"title\": title, \"link\": link})\n",
    "    if not headlines:\n",
    "        print(\"‚ö†Ô∏è No headlines found. Check ticker or date range!\")\n",
    "    return headlines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "22a0b0a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è No headlines found. Check ticker or date range!\n",
      "‚ùå No news found for this ticker/date range!\n"
     ]
    }
   ],
   "source": [
    "ticker = input(\"Enter stock ticker (e.g., AAPL): \").upper().strip()\n",
    "from_date = input(\"Enter start date (YYYY-MM-DD): \").strip()\n",
    "to_date = input(\"Enter end date (YYYY-MM-DD): \").strip()\n",
    "\n",
    "# Fetch news dynamically based on user input\n",
    "news = fetch_news(ticker, from_date, to_date)\n",
    "if not news:\n",
    "    print(\"‚ùå No news found for this ticker/date range!\")\n",
    "else:\n",
    "    print(f\"‚úÖ Collected {len(news)} headlines for {ticker}\")\n",
    "    for i, item in enumerate(news, 1):\n",
    "        title = item['title']\n",
    "        sentiment = get_sentiment_vader(title)\n",
    "        print(f\"{i}. {title}\")\n",
    "        print(f\"   Link: {item['link']}\")\n",
    "        print(f\"   Sentiment: {sentiment}\\n\")\n",
    "    print(f\"‚úÖ Collected {len(news)} headlines for visualization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "19c24071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå No data to visualize\n"
     ]
    }
   ],
   "source": [
    "if news:\n",
    "    sentiments = [get_sentiment_vader(item['title']) for item in news]\n",
    "    sentiment_counts = {\n",
    "        'Bullish': sentiments.count('Bullish'),\n",
    "        'Bearish': sentiments.count('Bearish'),\n",
    "        'Neutral': sentiments.count('Neutral')\n",
    "    }\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    colors = ['#06D6A0', '#EF476F', '#FFD166']\n",
    "    explode = (0.05, 0.05, 0.05)\n",
    "    wedges, texts, autotexts = plt.pie(\n",
    "        sentiment_counts.values(),\n",
    "        labels=sentiment_counts.keys(),\n",
    "        autopct=lambda p: f\"{p:.1f}%\\n({int(p*sum(sentiment_counts.values())/100)})\",\n",
    "        colors=colors,\n",
    "        explode=explode,\n",
    "        startangle=90,\n",
    "        textprops={'fontsize': 12, 'fontweight': 'bold'}\n",
    "    )\n",
    "    for text in texts + autotexts:\n",
    "        text.set_color('black')\n",
    "        text.set_fontsize(12)\n",
    "        text.set_fontweight('bold')\n",
    "    plt.title(f'Sentiment Distribution for {ticker}', fontsize=16, fontweight='bold', pad=20)\n",
    "    filename = f\"{ticker}_sentiment_pie.png\"\n",
    "    plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "    print(f\"üìä Saved: {filename}\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"‚ùå No data to visualize\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da19650a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå No news found for this ticker/date range!\n"
     ]
    }
   ],
   "source": [
    "if news:\n",
    "    # Sentiment counts\n",
    "    sentiments = [get_sentiment_vader(item['title']) for item in news]\n",
    "    bullish = sentiments.count('Bullish')\n",
    "    bearish = sentiments.count('Bearish')\n",
    "    neutral = sentiments.count('Neutral')\n",
    "    total = len(news)\n",
    "\n",
    "    # Overall signal\n",
    "    if bullish > bearish:\n",
    "        overall_signal = \"Bullish\"\n",
    "    elif bearish > bullish:\n",
    "        overall_signal = \"Bearish\"\n",
    "    else:\n",
    "        overall_signal = \"Neutral\"\n",
    "\n",
    "    # Top keywords\n",
    "    top_keywords = extract_keywords(news)\n",
    "\n",
    "    # Fetch earnings\n",
    "    earnings = fetch_earnings(ticker)\n",
    "\n",
    "    # Generate summary\n",
    "    summary = generate_summary(ticker, news, overall_signal, top_keywords)\n",
    "    print(summary)\n",
    "\n",
    "    # Print earnings if available\n",
    "    if earnings:\n",
    "        print(f\"\\nüìä Latest Earnings Report for {ticker}\")\n",
    "        print(\"=\" * 50)\n",
    "        print(f\"Reported Date:    {earnings['reported_date']}\")\n",
    "        print(f\"Actual EPS:       {earnings['actual_eps']}\")\n",
    "        print(f\"Estimated EPS:    {earnings['estimated_eps']}\")\n",
    "        print(f\"Surprise:         {earnings['surprise']}\")\n",
    "        print(f\"Surprise %:       {earnings['surprise_percent']}%\")\n",
    "        print(\"=\" * 50)\n",
    "    else:\n",
    "        print(f\"\\n‚ö†Ô∏è  No earnings data available for {ticker}\")\n",
    "\n",
    "    # Structured final report\n",
    "    final_report = {\n",
    "        \"ticker\": ticker,\n",
    "        \"date_range\": f\"{from_date} to {to_date}\",\n",
    "        \"headlines_analyzed\": total,\n",
    "        \"bullish\": bullish,\n",
    "        \"bearish\": bearish,\n",
    "        \"neutral\": neutral,\n",
    "        \"overall_signal\": overall_signal,\n",
    "        \"top_keywords\": top_keywords,\n",
    "        \"earnings\": earnings,\n",
    "        \"summary\": summary\n",
    "    }\n",
    "    print(\"\\nüìÑ Structured Report:\")\n",
    "    print(final_report)\n",
    "else:\n",
    "    print(\"‚ùå No news found for this ticker/date range!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e41fbef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7f1e4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f14fbc2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
